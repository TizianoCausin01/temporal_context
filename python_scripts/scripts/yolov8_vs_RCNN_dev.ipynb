{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "045596d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, yaml, sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline\n",
    "\n",
    "ENV = os.getenv(\"MY_ENV\", \"dev\")\n",
    "with open(\"../../config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "paths = config[ENV][\"paths\"]\n",
    "sys.path.append(paths[\"src_path\"])\n",
    "from image_processing.utils import read_video\n",
    "from image_processing.computational_models import detect_faces, make_corners\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f90c41af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "face_model_path = hf_hub_download(repo_id=\"arnabdhar/YOLOv8-Face-Detection\", filename=\"model.pt\")\n",
    "face_model = YOLO(face_model_path)\n",
    "person_model_path = 'yolov8n.pt'\n",
    "person_model = YOLO(person_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f5fab78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the model\n",
    "model = YOLO(\"yolov8n.pt\")  # or your custom weights\n",
    "\n",
    "# Print class labels\n",
    "print(model.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa4a7ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dir = f\"{paths['livingstone_lab']}/Stimuli/Movies/all_videos\"\n",
    "video_fn = os.listdir(video_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c62c732",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_vids = [fn for fn in video_fn if (\"IMG\" not in fn) and (\"YDX\" not in fn)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b6fd4826",
   "metadata": {},
   "outputs": [],
   "source": [
    "monkey_vids = [fn for fn in video_fn if \"IMG\" in fn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "18d6576d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ydx_vids = [fn for fn in video_fn if \"YDX\" in fn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eedee472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:04:45 - rank 1 YDXJ0090A.MP4 read successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fn = \"YDXJ0090A.MP4\"\n",
    "v = read_video(paths, 1, fn, vid_duration=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab74766",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = detect_faces(v, face_model, person_model, 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9467fd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "coords = loadmat(f\"{paths['livingstone_lab']}/tiziano/models/human_face_detection_{fn[:-4]}.mat\")['coords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4c3ca18d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# print and check\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(v.shape[\u001b[32m0\u001b[39m]):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[43mplt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m coords[\u001b[32m1\u001b[39m, i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m      5\u001b[39m         points = make_corners(*coords[\u001b[32m2\u001b[39m:, i])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/virtual_envs/temporal_context/lib/python3.12/site-packages/matplotlib/pyplot.py:3601\u001b[39m, in \u001b[36mimshow\u001b[39m\u001b[34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, colorizer, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001b[39m\n\u001b[32m   3579\u001b[39m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes.imshow)\n\u001b[32m   3580\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mimshow\u001b[39m(\n\u001b[32m   3581\u001b[39m     X: ArrayLike | PIL.Image.Image,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3599\u001b[39m     **kwargs,\n\u001b[32m   3600\u001b[39m ) -> AxesImage:\n\u001b[32m-> \u001b[39m\u001b[32m3601\u001b[39m     __ret = \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3602\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3603\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcmap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3604\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3605\u001b[39m \u001b[43m        \u001b[49m\u001b[43maspect\u001b[49m\u001b[43m=\u001b[49m\u001b[43maspect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3606\u001b[39m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3607\u001b[39m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m=\u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3608\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvmin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3609\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvmax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3610\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolorizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolorizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3611\u001b[39m \u001b[43m        \u001b[49m\u001b[43morigin\u001b[49m\u001b[43m=\u001b[49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3612\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3613\u001b[39m \u001b[43m        \u001b[49m\u001b[43minterpolation_stage\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterpolation_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3614\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilternorm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilternorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3615\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilterrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilterrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3616\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresample\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3617\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3618\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3619\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3620\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3621\u001b[39m     sci(__ret)\n\u001b[32m   3622\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m __ret\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/virtual_envs/temporal_context/lib/python3.12/site-packages/matplotlib/__init__.py:1524\u001b[39m, in \u001b[36m_preprocess_data.<locals>.inner\u001b[39m\u001b[34m(ax, data, *args, **kwargs)\u001b[39m\n\u001b[32m   1521\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(ax, *args, data=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m   1523\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1524\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1525\u001b[39m \u001b[43m            \u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1526\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcbook\u001b[49m\u001b[43m.\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1527\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbook\u001b[49m\u001b[43m.\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1529\u001b[39m     bound = new_sig.bind(ax, *args, **kwargs)\n\u001b[32m   1530\u001b[39m     auto_label = (bound.arguments.get(label_namer)\n\u001b[32m   1531\u001b[39m                   \u001b[38;5;129;01mor\u001b[39;00m bound.kwargs.get(label_namer))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/virtual_envs/temporal_context/lib/python3.12/site-packages/matplotlib/axes/_axes.py:5982\u001b[39m, in \u001b[36mAxes.imshow\u001b[39m\u001b[34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, colorizer, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[39m\n\u001b[32m   5979\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m aspect \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5980\u001b[39m     \u001b[38;5;28mself\u001b[39m.set_aspect(aspect)\n\u001b[32m-> \u001b[39m\u001b[32m5982\u001b[39m \u001b[43mim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5983\u001b[39m im.set_alpha(alpha)\n\u001b[32m   5984\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m im.get_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5985\u001b[39m     \u001b[38;5;66;03m# image does not already have clipping set, clip to Axes patch\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/virtual_envs/temporal_context/lib/python3.12/site-packages/matplotlib/image.py:685\u001b[39m, in \u001b[36m_ImageBase.set_data\u001b[39m\u001b[34m(self, A)\u001b[39m\n\u001b[32m    683\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(A, PIL.Image.Image):\n\u001b[32m    684\u001b[39m     A = pil_to_array(A)  \u001b[38;5;66;03m# Needed e.g. to apply png palette.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m685\u001b[39m \u001b[38;5;28mself\u001b[39m._A = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_normalize_image_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[38;5;28mself\u001b[39m._imcache = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    687\u001b[39m \u001b[38;5;28mself\u001b[39m.stale = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/virtual_envs/temporal_context/lib/python3.12/site-packages/matplotlib/image.py:646\u001b[39m, in \u001b[36m_ImageBase._normalize_image_array\u001b[39m\u001b[34m(A)\u001b[39m\n\u001b[32m    640\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    641\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_normalize_image_array\u001b[39m(A):\n\u001b[32m    642\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    643\u001b[39m \u001b[33;03m    Check validity of image-like input *A* and normalize it to a format suitable for\u001b[39;00m\n\u001b[32m    644\u001b[39m \u001b[33;03m    Image subclasses.\u001b[39;00m\n\u001b[32m    645\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m646\u001b[39m     A = \u001b[43mcbook\u001b[49m\u001b[43m.\u001b[49m\u001b[43msafe_masked_invalid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    647\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m A.dtype != np.uint8 \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.can_cast(A.dtype, \u001b[38;5;28mfloat\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msame_kind\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    648\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mImage data of dtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mA.dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m cannot be \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    649\u001b[39m                         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mconverted to float\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/virtual_envs/temporal_context/lib/python3.12/site-packages/matplotlib/cbook.py:684\u001b[39m, in \u001b[36msafe_masked_invalid\u001b[39m\u001b[34m(x, copy)\u001b[39m\n\u001b[32m    683\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msafe_masked_invalid\u001b[39m(x, copy=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m684\u001b[39m     x = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubok\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    685\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x.dtype.isnative:\n\u001b[32m    686\u001b[39m         \u001b[38;5;66;03m# If we have already made a copy, do the byteswap in place, else make a\u001b[39;00m\n\u001b[32m    687\u001b[39m         \u001b[38;5;66;03m# copy with the byte order swapped.\u001b[39;00m\n\u001b[32m    688\u001b[39m         \u001b[38;5;66;03m# Swap to native order.\u001b[39;00m\n\u001b[32m    689\u001b[39m         x = x.byteswap(inplace=copy).view(x.dtype.newbyteorder(\u001b[33m'\u001b[39m\u001b[33mN\u001b[39m\u001b[33m'\u001b[39m))\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print and check\n",
    "for i in range(v.shape[0]):\n",
    "    plt.imshow(v[i, :, :, :])\n",
    "    if coords[1, i] is not None:\n",
    "        points = make_corners(*coords[2:, i])\n",
    "        plt.plot(points[:, 0], points[:, 1], 'r-', linewidth=2)\n",
    "    if coords[0, i] == 0:\n",
    "        label = \"no face\"\n",
    "    elif coords[0, i] == 1:\n",
    "        label = f\"face {coords[1, i]}\"\n",
    "    elif coords[0, i] == 2:\n",
    "        label = f\"occluded {coords[1, i]}\"\n",
    "    plt.text(1, 0.8, label, fontsize=12,\n",
    "            bbox=dict(facecolor=\"white\", edgecolor=\"black\", boxstyle=\"round,pad=0.3\"))\n",
    "    plt.show()\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf326a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temporal_context",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
